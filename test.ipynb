{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "995a5e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = [\n",
    "    {\n",
    "        \"venue\": \"CVPR\",\n",
    "        \"tracks\": [\n",
    "            \"3D from multi-view and sensors\",\n",
    "            \"3D from single images\",\n",
    "            \"Adversarial attack and defense\",\n",
    "            \"Autonomous driving\",\n",
    "            \"Biometrics\",\n",
    "            \"Computational imaging\",\n",
    "            \"Computer vision for social good\",\n",
    "            \"Computer vision theory\",\n",
    "            \"Datasets and evaluation\",\n",
    "            \"Deep learning architectures and techniques\",\n",
    "            \"Document analysis and understanding\",\n",
    "            \"Efficient and scalable vision\",\n",
    "            \"Embodied vision: Active agents, simulation\",\n",
    "            \"Event-based cameras\",\n",
    "            \"Explainable computer vision\",\n",
    "            \"Humans: Face, body, pose, gesture, movement\",\n",
    "            \"Image and video synthesis and generation\",\n",
    "            \"Low-level vision\",\n",
    "            \"Machine learning (other than deep learning)\",\n",
    "            \"Medical and biological vision, cell microscopy\",\n",
    "            \"Multimodal learning\",\n",
    "            \"Optimization methods (other than deep learning)\",\n",
    "            \"Photogrammetry and remote sensing\",\n",
    "            \"Physics-based vision and shape-from-X\",\n",
    "            \"Recognition: Categorization, detection, retrieval\",\n",
    "            \"Representation learning\",\n",
    "            \"Computer Vision for Robotics\",\n",
    "            \"Scene analysis and understanding\",\n",
    "            \"Segmentation, grouping and shape analysis\",\n",
    "            \"Self-, semi-, meta- and unsupervised learning\",\n",
    "            \"Transfer/ low-shot/ continual/ long-tail learning\",\n",
    "            \"Transparency, fairness, accountability, privacy and ethics in vision\",\n",
    "            \"Video: Action and event understanding\",\n",
    "            \"Video: Low-level analysis, motion, and tracking\",\n",
    "            \"Vision + graphics\",\n",
    "            \"Vision, language, and reasoning\",\n",
    "            \"Vision applications and systems\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"venue\": \"NeurIPS\",\n",
    "        \"tracks\": [\n",
    "            \"Applications (e.g., vision, language, speech and audio, Creative AI)\",\n",
    "            \"Deep learning (e.g., architectures, generative models, optimization for deep networks, foundation models, LLMs)\",\n",
    "            \"Evaluation (e.g., methodology, meta studies, replicability and validity, human-in-the-loop)\",\n",
    "            \"General machine learning (supervised, unsupervised, online, active, etc.)\",\n",
    "            \"Infrastructure (e.g., libraries, improved implementation and scalability, distributed solutions)\",\n",
    "            \"Machine learning for sciences (e.g. climate, health, life sciences, physics, social sciences)\",\n",
    "            \"Neuroscience and cognitive science (e.g., neural coding, brain-computer interfaces)\",\n",
    "            \"Optimization (e.g., convex and non-convex, stochastic, robust)\",\n",
    "            \"Probabilistic methods (e.g., variational inference, causal inference, Gaussian processes)\",\n",
    "            \"Reinforcement learning (e.g., decision and control, planning, hierarchical RL, robotics)\",\n",
    "            \"Social and economic aspects of machine learning (e.g., fairness, interpretability, human-AI interaction, privacy, safety, strategic behavior)\",\n",
    "            \"Theory (e.g., control theory, learning theory, algorithmic game theory)\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"venue\": \"IEEE VR\",\n",
    "        \"tracks\": [\n",
    "            \"360Â° video\",\n",
    "            \"3D and volumetric display and projection technology\",\n",
    "            \"3D authoring\",\n",
    "            \"3D user interfaces\",\n",
    "            \"Accessibility of immersive interfaces\",\n",
    "            \"Audio interfaces and rendering\",\n",
    "            \"Collaborative interactions\",\n",
    "            \"Computer graphics techniques\",\n",
    "            \"Crowd simulation\",\n",
    "            \"Cybersickness\",\n",
    "            \"Diversity and gender issues\",\n",
    "            \"Embodied agents, virtual humans and (self-)avatars\",\n",
    "            \"Ethical issues\",\n",
    "            \"Evaluation methods\",\n",
    "            \"Haptic interfaces and rendering\",\n",
    "            \"Human factors and ergonomics\",\n",
    "            \"Immersive analytics and visualization\",\n",
    "            \"Immersive applications and games\",\n",
    "            \"Input devices\",\n",
    "            \"Locomotion and navigation\",\n",
    "            \"Mediated and diminished reality\",\n",
    "            \"Mobile, desktop or hybrid 3DUIs\",\n",
    "            \"Modeling and simulation\",\n",
    "            \"Multi-user and distributed systems\",\n",
    "            \"Multimodal capturing and reconstruction\",\n",
    "            \"Multimodal/cross-modal interaction and perception\",\n",
    "            \"Multisensory interfaces and rendering\",\n",
    "            \"Perception and cognition\",\n",
    "            \"Presence, body ownership, and agency\",\n",
    "            \"Redirection\",\n",
    "            \"Software architectures, toolkits, and engineering\",\n",
    "            \"Teleoperation and telepresence\",\n",
    "            \"Therapy and rehabilitation\",\n",
    "            \"Touch, tangible and gesture interfaces\",\n",
    "            \"Tracking\",\n",
    "            \"User experience and usability\",\n",
    "            \"XR technology infrastructure\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"venue\": \"ICLR\",\n",
    "        \"tracks\": [\n",
    "            \"unsupervised, self-supervised, semi-supervised, and supervised representation learning\",\n",
    "            \"transfer learning, meta learning, and lifelong learning\",\n",
    "            \"reinforcement learning\",\n",
    "            \"representation learning for computer vision, audio, language, and other modalities\",\n",
    "            \"metric learning, kernel learning, and sparse coding\",\n",
    "            \"probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)\",\n",
    "            \"generative models\",\n",
    "            \"causal reasoning\",\n",
    "            \"optimization\",\n",
    "            \"learning theory\",\n",
    "            \"learning on graphs and other geometries & topologies\",\n",
    "            \"societal considerations including fairness, safety, privacy\",\n",
    "            \"visualization or interpretation of learned representations\",\n",
    "            \"datasets and benchmarks\",\n",
    "            \"infrastructure, software libraries, hardware, etc.\",\n",
    "            \"neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)\",\n",
    "            \"applications to robotics, autonomy, planning\",\n",
    "            \"applications to neuroscience & cognitive science\",\n",
    "            \"applications to physical sciences (physics, chemistry, biology, etc.)\",\n",
    "            \"general machine learning\",\n",
    "        ],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f1aed",
   "metadata": {},
   "source": [
    "# Present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fa1b5f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Track\", \"User\", \"Matteo\"])\n",
    "for track in tracks:\n",
    "    venue = track[\"venue\"]\n",
    "    for subtrack in track[\"tracks\"]:\n",
    "        df = pd.concat(\n",
    "            [\n",
    "                df,\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"Track\": [subtrack.capitalize()],\n",
    "                    }\n",
    "                ),\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "df = df.sort_values(by=\"Track\").reset_index(drop=True)\n",
    "df.to_excel(\"tracks.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d68bd0",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c3fd1e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unsupervised, self-supervised, semi-supervised, and supervised representation learning',\n",
       " 'transfer learning, meta learning, and lifelong learning',\n",
       " 'reinforcement learning',\n",
       " 'representation learning for computer vision, audio, language, and other modalities',\n",
       " 'metric learning, kernel learning, and sparse coding',\n",
       " 'probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)',\n",
       " 'generative models',\n",
       " 'causal reasoning',\n",
       " 'optimization',\n",
       " 'learning theory',\n",
       " 'learning on graphs and other geometries & topologies',\n",
       " 'societal considerations including fairness, safety, privacy',\n",
       " 'visualization or interpretation of learned representations',\n",
       " 'datasets and benchmarks',\n",
       " 'infrastructure, software libraries, hardware, etc.',\n",
       " 'neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)',\n",
       " 'applications to robotics, autonomy, planning',\n",
       " 'applications to neuroscience & cognitive science',\n",
       " 'applications to physical sciences (physics, chemistry, biology, etc.)',\n",
       " 'general machine learning (i.e., none of the above)']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_raw = \"\"\"\n",
    "unsupervised, self-supervised, semi-supervised, and supervised representation learning\n",
    "transfer learning, meta learning, and lifelong learning\n",
    "reinforcement learning\n",
    "representation learning for computer vision, audio, language, and other modalities\n",
    "metric learning, kernel learning, and sparse coding\n",
    "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)\n",
    "generative models\n",
    "causal reasoning\n",
    "optimization\n",
    "learning theory\n",
    "learning on graphs and other geometries & topologies\n",
    "societal considerations including fairness, safety, privacy\n",
    "visualization or interpretation of learned representations\n",
    "datasets and benchmarks\n",
    "infrastructure, software libraries, hardware, etc.\n",
    "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)\n",
    "applications to robotics, autonomy, planning\n",
    "applications to neuroscience & cognitive science\n",
    "applications to physical sciences (physics, chemistry, biology, etc.)\n",
    "general machine learning (i.e., none of the above)\n",
    "\"\"\"\n",
    "\n",
    "s_parsed = s_raw.strip().split(\"\\n\")\n",
    "s_parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d356951d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46371a05",
   "metadata": {},
   "source": [
    "# Compiled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d6610b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Track</th>\n",
       "      <th>Alessio Fagioli</th>\n",
       "      <th>Alessio Mecca</th>\n",
       "      <th>Anxhelo Diko</th>\n",
       "      <th>Diego Bellani</th>\n",
       "      <th>Federico Fontana</th>\n",
       "      <th>Marco Cascio</th>\n",
       "      <th>Marco Raoul Marini</th>\n",
       "      <th>Matteo Basile</th>\n",
       "      <th>Romeo Lanzino</th>\n",
       "      <th>Valerio Venanzi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360Â° video</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3d and volumetric display and projection techn...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3d authoring</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3d from multi-view and sensors</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3d from single images</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Vision, language, and reasoning</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Visualization or interpretation of learned rep...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Xr technology infrastructure</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>ML compilers and runtimes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Specialized hardware for machine learning</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Track  Alessio Fagioli  \\\n",
       "0                                           360Â° video            False   \n",
       "1    3d and volumetric display and projection techn...            False   \n",
       "2                                         3d authoring            False   \n",
       "3                       3d from multi-view and sensors            False   \n",
       "4                                3d from single images            False   \n",
       "..                                                 ...              ...   \n",
       "103                    Vision, language, and reasoning             True   \n",
       "104  Visualization or interpretation of learned rep...            False   \n",
       "105                       Xr technology infrastructure            False   \n",
       "106                          ML compilers and runtimes            False   \n",
       "107          Specialized hardware for machine learning            False   \n",
       "\n",
       "     Alessio Mecca  Anxhelo Diko  Diego Bellani  Federico Fontana  \\\n",
       "0            False         False          False             False   \n",
       "1            False         False          False             False   \n",
       "2            False         False          False             False   \n",
       "3            False         False          False             False   \n",
       "4            False         False          False             False   \n",
       "..             ...           ...            ...               ...   \n",
       "103          False         False          False             False   \n",
       "104          False         False          False             False   \n",
       "105          False         False          False             False   \n",
       "106          False         False           True             False   \n",
       "107          False         False           True             False   \n",
       "\n",
       "     Marco Cascio  Marco Raoul Marini  Matteo Basile  Romeo Lanzino  \\\n",
       "0           False               False          False          False   \n",
       "1           False               False          False          False   \n",
       "2           False               False          False          False   \n",
       "3           False               False          False          False   \n",
       "4           False               False          False          False   \n",
       "..            ...                 ...            ...            ...   \n",
       "103         False               False          False          False   \n",
       "104         False               False          False          False   \n",
       "105         False               False          False          False   \n",
       "106         False               False          False          False   \n",
       "107         False               False          False          False   \n",
       "\n",
       "     Valerio Venanzi  \n",
       "0              False  \n",
       "1              False  \n",
       "2              False  \n",
       "3              False  \n",
       "4              False  \n",
       "..               ...  \n",
       "103             True  \n",
       "104            False  \n",
       "105            False  \n",
       "106            False  \n",
       "107            False  \n",
       "\n",
       "[108 rows x 11 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compiled = pd.read_csv(\"tracks.csv\")\n",
    "df_compiled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071226d7",
   "metadata": {},
   "source": [
    "## All tracks done by the lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "348f01dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Applications to neuroscience & cognitive science': ['Alessio Fagioli'],\n",
       " 'Biometrics': ['Alessio Fagioli'],\n",
       " 'Cybersickness': ['Matteo Basile'],\n",
       " 'Datasets and benchmarks': ['Alessio Fagioli', 'Romeo Lanzino'],\n",
       " 'Datasets and evaluation': ['Alessio Fagioli', 'Romeo Lanzino'],\n",
       " 'Deep learning (e.g., architectures, generative models, optimization for deep networks, foundation models, llms)': ['Alessio Fagioli',\n",
       "  'Federico Fontana'],\n",
       " 'Deep learning architectures and techniques': ['Alessio Fagioli'],\n",
       " 'Diversity and gender issues': ['Romeo Lanzino'],\n",
       " 'Efficient and scalable vision': ['Federico Fontana'],\n",
       " 'Evaluation (e.g., methodology, meta studies, replicability and validity, human-in-the-loop)': ['Romeo Lanzino'],\n",
       " 'Evaluation methods': ['Romeo Lanzino'],\n",
       " 'Generative models': ['Valerio Venanzi'],\n",
       " 'Humans: face, body, pose, gesture, movement': ['Alessio Fagioli'],\n",
       " 'Image and video synthesis and generation': ['Federico Fontana'],\n",
       " 'Immersive applications and games': ['Matteo Basile'],\n",
       " 'Infrastructure (e.g., libraries, improved implementation and scalability, distributed solutions)': ['Diego Bellani'],\n",
       " 'Infrastructure, software libraries, hardware, etc.': ['Diego Bellani'],\n",
       " 'Learning on graphs and other geometries & topologies': ['Valerio Venanzi'],\n",
       " 'Low-level vision': ['Alessio Fagioli'],\n",
       " 'Multimodal learning': ['Alessio Fagioli'],\n",
       " 'Neuroscience and cognitive science (e.g., neural coding, brain-computer interfaces)': ['Alessio Fagioli'],\n",
       " 'Optimization (e.g., convex and non-convex, stochastic, robust)': ['Federico Fontana'],\n",
       " 'Perception and cognition': ['Alessio Fagioli'],\n",
       " 'Recognition: categorization, detection, retrieval': ['Alessio Fagioli'],\n",
       " 'Reinforcement learning': ['Alessio Fagioli'],\n",
       " 'Segmentation, grouping and shape analysis': ['Alessio Fagioli'],\n",
       " 'Self-, semi-, meta- and unsupervised learning': ['Alessio Fagioli',\n",
       "  'Romeo Lanzino'],\n",
       " 'Software architectures, toolkits, and engineering': ['Diego Bellani'],\n",
       " 'Tracking': ['Alessio Fagioli'],\n",
       " 'Transfer learning, meta learning, and lifelong learning': ['Alessio Fagioli',\n",
       "  'Romeo Lanzino'],\n",
       " 'Transfer/ low-shot/ continual/ long-tail learning': ['Alessio Fagioli',\n",
       "  'Romeo Lanzino'],\n",
       " 'Unsupervised, self-supervised, semi-supervised, and supervised representation learning': ['Alessio Fagioli'],\n",
       " 'Video: low-level analysis, motion, and tracking': ['Alessio Fagioli'],\n",
       " 'Vision, language, and reasoning': ['Alessio Fagioli', 'Valerio Venanzi'],\n",
       " 'ML compilers and runtimes': ['Diego Bellani'],\n",
       " 'Specialized hardware for machine learning': ['Diego Bellani']}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "tracks = df_compiled[df_compiled.drop([\"Track\"], axis=\"columns\").any(axis=1)][\"Track\"].tolist()\n",
    "people = {c for c in df_compiled.columns if c not in [\"Track\"]}\n",
    "people_tracks = {}\n",
    "for person in people:\n",
    "    df_compiled_per_person = df_compiled[[\"Track\", person]].dropna()\n",
    "    person_tracks = df_compiled_per_person[df_compiled_per_person[person] == True][\n",
    "        \"Track\"\n",
    "    ].tolist()\n",
    "    people_tracks[person] = person_tracks\n",
    "    # if person_tracks:\n",
    "    #     people_tracks[person] = person_tracks\n",
    "# merge all tracks into a single dataframe\n",
    "tracks_people = {track: [p for p in people if track in people_tracks[p]] for track in tracks}\n",
    "with open(\"tracks_people_full.yaml\", \"w\") as f:\n",
    "    yaml.dump(tracks_people, f, sort_keys=True, indent=4)\n",
    "tracks_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e511977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep learning architectures ['Deep learning (e.g., architectures, generative models, optimization for deep networks, foundation models, llms)', 'Deep learning architectures and techniques']\n",
      "Datasets ['Datasets and benchmarks', 'Datasets and evaluation']\n",
      "Benchmarking and evaluation ['Datasets and benchmarks', 'Datasets and evaluation', 'Evaluation (e.g., methodology, meta studies, replicability and validity, human-in-the-loop)', 'Evaluation methods']\n",
      "Low-level  vision ['Low-level vision', 'Video: low-level analysis, motion, and tracking']\n",
      "Specialized hardware for ML ['Infrastructure, software libraries, hardware, etc.', 'Specialized hardware for machine learning']\n",
      "Infrastructure, libraries, architectures, compilers ['Deep learning (e.g., architectures, generative models, optimization for deep networks, foundation models, llms)', 'Deep learning architectures and techniques', 'Infrastructure (e.g., libraries, improved implementation and scalability, distributed solutions)', 'Infrastructure, software libraries, hardware, etc.', 'Software architectures, toolkits, and engineering', 'ML compilers and runtimes']\n",
      "Text generation and retrieval, LLMs ['Deep learning (e.g., architectures, generative models, optimization for deep networks, foundation models, llms)', 'Generative models']\n",
      "Image and video generation ['Image and video synthesis and generation']\n",
      "Optimization methods ['Deep learning (e.g., architectures, generative models, optimization for deep networks, foundation models, llms)', 'Optimization (e.g., convex and non-convex, stochastic, robust)']\n",
      "Meta, few-shot, and continual learning ['Evaluation (e.g., methodology, meta studies, replicability and validity, human-in-the-loop)', 'Self-, semi-, meta- and unsupervised learning', 'Transfer learning, meta learning, and lifelong learning', 'Transfer/ low-shot/ continual/ long-tail learning']\n",
      "Tracking, detection, and biometrics ['Biometrics', 'Evaluation (e.g., methodology, meta studies, replicability and validity, human-in-the-loop)', 'Humans: face, body, pose, gesture, movement', 'Recognition: categorization, detection, retrieval', 'Tracking', 'Video: low-level analysis, motion, and tracking']\n",
      "Applications to neuroscience and medical images ['Applications to neuroscience & cognitive science', 'Neuroscience and cognitive science (e.g., neural coding, brain-computer interfaces)']\n",
      "Fairness, ethics ['Diversity and gender issues']\n",
      "Efficiency in deep learning ['Efficient and scalable vision']\n",
      "Self, semi, and unsupervised learning ['Self-, semi-, meta- and unsupervised learning', 'Unsupervised, self-supervised, semi-supervised, and supervised representation learning']\n",
      "Language and vision, VLMs ['Efficient and scalable vision', 'Low-level vision', 'Vision, language, and reasoning']\n",
      "VR, AR, and XR applications ['Immersive applications and games']\n",
      "23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Cybersickness': ['Matteo Basile'],\n",
       " 'Learning on graphs and other geometries & topologies': ['Valerio Venanzi'],\n",
       " 'Multimodal learning': ['Alessio Fagioli'],\n",
       " 'Perception and cognition': ['Alessio Fagioli'],\n",
       " 'Reinforcement learning': ['Alessio Fagioli'],\n",
       " 'Segmentation, grouping and shape analysis': ['Alessio Fagioli'],\n",
       " 'Deep learning architectures': ['Alessio Fagioli', 'Federico Fontana'],\n",
       " 'Datasets': ['Alessio Fagioli', 'Romeo Lanzino'],\n",
       " 'Benchmarking and evaluation': ['Romeo Lanzino'],\n",
       " 'Low-level  vision': ['Alessio Fagioli'],\n",
       " 'Specialized hardware for ML': ['Diego Bellani'],\n",
       " 'Infrastructure, libraries, architectures, compilers': ['Diego Bellani'],\n",
       " 'Text generation and retrieval, LLMs': ['Valerio Venanzi'],\n",
       " 'Image and video generation': ['Federico Fontana'],\n",
       " 'Optimization methods': ['Federico Fontana'],\n",
       " 'Meta, few-shot, and continual learning': ['Alessio Fagioli',\n",
       "  'Romeo Lanzino'],\n",
       " 'Tracking, detection, and biometrics': ['Alessio Fagioli'],\n",
       " 'Applications to neuroscience and medical images': ['Alessio Fagioli'],\n",
       " 'Fairness, ethics': ['Romeo Lanzino'],\n",
       " 'Efficiency in deep learning': ['Federico Fontana'],\n",
       " 'Self, semi, and unsupervised learning': ['Alessio Fagioli'],\n",
       " 'Language and vision, VLMs': ['Alessio Fagioli', 'Valerio Venanzi'],\n",
       " 'VR, AR, and XR applications': ['Matteo Basile']}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge some categories\n",
    "macrotracks = {\n",
    "    \"Deep learning architectures\": [t for t in tracks if \"deep learning\" in t.lower()],\n",
    "    \"Datasets\": [t for t in tracks if \"dataset\" in t.lower() or \"benchmark\" in t.lower()],\n",
    "    \"Benchmarking and evaluation\": [t for t in tracks if \"benchmark\" in t.lower() or \"evaluation\" in t.lower() or \"validation\" in t.lower()],\n",
    "    \"Low-level  vision\": [t for t in tracks if \"low-level\" in t.lower()],\n",
    "    \"Specialized hardware for ML\": [t for t in tracks if \"hardware\" in t.lower()],\n",
    "    \"Infrastructure, libraries, architectures, compilers\": [t for t in tracks if \"infrastructure\" in t.lower() or \"library\" in t.lower() or \"compiler\" in t.lower() or \"architectures\" in t.lower()],\n",
    "    \"Text generation and retrieval, LLMs\": [t for t in tracks if \"generative\" in t.lower()],\n",
    "    \"Image and video generation\": [t for t in tracks if \"generation\" in t.lower() or \"synthesis\" in t.lower()],\n",
    "    \"Optimization methods\": [t for t in tracks if \"optimization\" in t.lower()],\n",
    "    \"Meta, few-shot, and continual learning\": [t for t in tracks if \"meta\" in t.lower() or \"few-shot\" in t.lower() or \"continual\" in t.lower() or \"long-tail\" in t.lower()],\n",
    "    \"Tracking, detection, and biometrics\": [t for t in tracks if \"tracking\" in t.lower() or \"biometrics\" in t.lower() or \"human\" in t.lower() or \"recognition\" in t.lower()],\n",
    "    \"Applications to neuroscience and medical images\": [t for t in tracks if \"neuroscience\" in t.lower() or \"medical\" in t.lower() or \"biological\" in t.lower()],\n",
    "    \"Fairness, ethics\": [t for t in tracks if \"diversity\" in t.lower() or \"ethics\" in t.lower() or \"privacy\" in t.lower() or \"accountability\" in t.lower()],\n",
    "    \"Efficiency in deep learning\": [t for t in tracks if \"efficient\" in t.lower() or \"scalable\" in t.lower()],\n",
    "    \"Self, semi, and unsupervised learning\": [t for t in tracks if \"self\" in t.lower() or \"semi\" in t.lower() or \"unsupervised\" in t.lower()],\n",
    "    \"Language and vision, VLMs\": [t for t in tracks if \"language\" in t.lower() or \"vlm\" in t.lower() or \"vision\" in t.lower()],\n",
    "    \"VR, AR, and XR applications\": [t for t in tracks if \"vr\" in t.lower() or \"immersive\" in t.lower() or \"xr\" in t.lower()],\n",
    "}\n",
    "for macrotrack in macrotracks:\n",
    "    print(macrotrack, macrotracks[macrotrack])\n",
    "    tracks_people[macrotrack] = set()\n",
    "    for track in macrotracks[macrotrack]:\n",
    "        if track in tracks_people:\n",
    "            tracks_people[macrotrack] = tracks_people[macrotrack].union(set(tracks_people[track]))\n",
    "            tracks_people.pop(track)\n",
    "    tracks_people[macrotrack] = sorted(list(tracks_people[macrotrack]))\n",
    "print(len(tracks_people))\n",
    "with open(\"tracks_people_merged.yaml\", \"w\") as f:\n",
    "    yaml.dump(tracks_people, f, sort_keys=True, indent=4)\n",
    "tracks_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ad9eda70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creates the df\n",
    "# people_tracks_df = pd.DataFrame(columns=sorted(all_tracks))\n",
    "# for person in people_tracks:\n",
    "#     people_tracks_df = pd.concat(\n",
    "#         [\n",
    "#             people_tracks_df,\n",
    "#             pd.DataFrame.from_dict(\n",
    "#                 {\n",
    "#                     person: [\n",
    "#                         True if track in people_tracks[person] else False\n",
    "#                         for track in all_tracks\n",
    "#                     ]\n",
    "#                 }\n",
    "#             ).T.rename(columns={p: c for p, c in enumerate(all_tracks)}),\n",
    "#         ],\n",
    "#         axis=0,\n",
    "#     )\n",
    "# people_tracks_df = people_tracks_df.to_csv(\"people_tracks.csv\", index=True)\n",
    "# people_tracks_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2hp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
