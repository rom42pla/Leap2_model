{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "04b3dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.ml2hp import MotionLeap2Dataset\n",
    "from datasets.mmhgdhgr import MultiModalHandGestureDatasetForHandGestureRecognition\n",
    "from os.path import join, isdir\n",
    "from os import listdir\n",
    "import yaml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3ddb3d",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c2fa5f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_results(checkpoints_path, dataset_name):\n",
    "    assert dataset_name in [\"ml2hp\", \"mmhgdhgr\", \"tiny_hgr\"], \"Dataset name must be 'ml2hp', 'mmhgdhgr', 'tiny_hgr.\"\n",
    "    # if dataset_name == \"ml2hp\":\n",
    "    #     subject_ids = MotionLeap2Dataset._get_subject_ids()\n",
    "    # else:\n",
    "    #     subject_ids = MultiModalHandGestureDatasetForHandGestureRecognition._get_subject_ids()\n",
    "    data = {}\n",
    "    metrics = []\n",
    "    for checkpoint_name in sorted(listdir(checkpoints_path)):\n",
    "        # check if the checkpoint has complete experiments\n",
    "        subjects_in_checkpoint = []\n",
    "        for folder in listdir(join(checkpoints_path, checkpoint_name)):\n",
    "            if (\n",
    "                # folder in subject_ids\n",
    "                isdir(join(checkpoints_path, checkpoint_name, folder))\n",
    "                and \"metrics.yaml\"\n",
    "                in listdir(join(checkpoints_path, checkpoint_name, folder))\n",
    "            ):\n",
    "                subjects_in_checkpoint.append(folder)\n",
    "        # skips empty checkpoints\n",
    "        if len(subjects_in_checkpoint) < 1:\n",
    "            print(f\"Skipping checkpoint {checkpoint_name} as it has no valid subjects.\")\n",
    "            continue\n",
    "        # loads the cfg used\n",
    "        with open(join(checkpoints_path, checkpoint_name, \"cfg.yaml\")) as f:\n",
    "            cfg = yaml.safe_load(f)\n",
    "        # initialize the data dict for this checkpoint\n",
    "        metrics_per_run = []\n",
    "        # loops over each subject\n",
    "        for subject_id in subjects_in_checkpoint:\n",
    "            # load the metrics for this subject\n",
    "            with open(\n",
    "                join(checkpoints_path, checkpoint_name, subject_id, \"metrics.yaml\")\n",
    "            ) as f:\n",
    "                metrics_per_run.append(yaml.safe_load(f)[0])\n",
    "        # compute the mean metrics for this checkpoint\n",
    "        metrics_per_run = pd.DataFrame(metrics_per_run)\n",
    "        metrics_per_run_mean, metrics_per_run_std = (\n",
    "            metrics_per_run.mean(),\n",
    "            metrics_per_run.std(),\n",
    "        )\n",
    "        # parses some numbers\n",
    "        for col in metrics_per_run.columns:\n",
    "            for df in [metrics_per_run_mean, metrics_per_run_std]:\n",
    "                if col.startswith(\"cls_\"):\n",
    "                    df[col] = (df[col] * 100).round(3)\n",
    "                elif col.startswith(\"num_params\"):\n",
    "                    df[col] = (df[col] / 1e6)\n",
    "                elif col.startswith(\"time_test\"):\n",
    "                    df[col] = (df[col] * 1e3).round(2)\n",
    "                # metrics_per_run[col] = metrics_per_run_mean.astype(str) + \" ± \" + metrics_per_run_std.astype(str)\n",
    "        metrics_per_run = (\n",
    "            metrics_per_run_mean.astype(str) + \" ± \" + metrics_per_run_std.astype(str)\n",
    "        )\n",
    "        metrics_per_run[\"num_params_test\"] = f\"{metrics_per_run_mean[\"num_params_test\"].round(1):.1f}\"\n",
    "        # for col in metrics_per_run.columns:\n",
    "        #     if col.startswith(\"num_params\"):\n",
    "        #         metrics_per_run[col] = metrics_per_run_mean[col].round(1)\n",
    "        for metric in [\n",
    "            \"validation\",\n",
    "            \"normalize_landmarks\",\n",
    "            \"image_backbone_name\",\n",
    "            \"landmarks_backbone_name\",\n",
    "            \"use_horizontal_landmarks\",\n",
    "            \"use_vertical_landmarks\",\n",
    "            \"use_horizontal_image\",\n",
    "            \"use_vertical_image\",\n",
    "        ]:\n",
    "            metrics_per_run[metric] = cfg[metric]\n",
    "        # metrics_per_run[\"normalize_landmarks\"] = cfg[\"normalize_landmarks\"]\n",
    "        # metrics_per_run[\"image_backbone\"] = cfg[\"image_backbone_name\"]\n",
    "        # metrics_per_run[\"landmarks_backbone\"] = cfg[\"landmarks_backbone_name\"]\n",
    "        # append to the metrics list\n",
    "        metrics.append(metrics_per_run)\n",
    "\n",
    "    # parses the metrics into a DataFrame\n",
    "    metrics = pd.DataFrame(metrics)\n",
    "    metrics = metrics[\n",
    "        [\n",
    "            \"validation\",\n",
    "            \"image_backbone_name\",\n",
    "            \"use_horizontal_image\",\n",
    "            \"use_vertical_image\",\n",
    "            \"landmarks_backbone_name\",\n",
    "            \"use_horizontal_landmarks\",\n",
    "            \"use_vertical_landmarks\",\n",
    "            \"normalize_landmarks\",\n",
    "            \"cls_acc_test\",\n",
    "            \"cls_f1_test\",\n",
    "            \"cls_prec_test\",\n",
    "            \"cls_rec_test\",\n",
    "            \"cls_loss_test\",\n",
    "            \"num_params_test\",\n",
    "            \"time_test\",\n",
    "        ]\n",
    "    ]\n",
    "    metrics = metrics.rename(\n",
    "        columns={\n",
    "            \"validation\": \"Validation\",\n",
    "            \"normalize_landmarks\": \"Normalized landmarks\",\n",
    "            \"landmarks_backbone_name\": \"Landmarks backbone\",\n",
    "            \"use_horizontal_landmarks\": \"H landmarks\",\n",
    "            \"use_vertical_landmarks\": \"V landmarks\",\n",
    "            \"use_horizontal_image\": \"H image\",\n",
    "            \"use_vertical_image\": \"V image\",\n",
    "            \"image_backbone_name\": \"Image backbone\",\n",
    "            \"cls_acc_test\": \"Accuracy (\\\\%) $\\\\uparrow$\",\n",
    "            \"cls_f1_test\": \"F1 (\\\\%) $\\\\uparrow$\",\n",
    "            \"cls_prec_test\": \"Precision (\\\\%) $\\\\uparrow$\",\n",
    "            \"cls_rec_test\": \"Recall (\\\\%) $\\\\uparrow$\",\n",
    "            \"cls_loss_test\": \"Loss $\\\\downarrow$\",\n",
    "            \"num_params_test\": \"\\\\# Params (M)\",\n",
    "            \"time_test\": \"Inference time (ms) $\\\\downarrow$\",\n",
    "        }\n",
    "    )\n",
    "    metrics = metrics.replace({\n",
    "        \"linear\": \"Linear\",\n",
    "        \"mlp\": \"MLP\",\n",
    "\n",
    "        \"clip-b\": \"CLIP-B \\\\cite{clip}\",\n",
    "        \"convnextv2-b\": \"ConvNeXt V2-B \\\\cite{convnextv2}\",\n",
    "        \"convnextv2-t\": \"ConvNeXt V2-T \\\\cite{convnextv2}\",\n",
    "        \"dinov2-b\": \"DINOv2-B \\\\cite{dinov2}\",\n",
    "        \"dinov2-s\": \"DINOv2-S \\\\cite{dinov2}\",\n",
    "        \"resnet18\": \"ResNet-18 \\\\cite{resnet, resnet_strikes_back}\",\n",
    "\n",
    "        None: \"-\",\n",
    "    })\n",
    "    metrics = metrics.sort_values(by=[\"Image backbone\", \"\\\\# Params (M)\"])\n",
    "    metrics = metrics.reset_index(drop=True)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca042d2",
   "metadata": {},
   "source": [
    "# Tables for the manuscript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7ecb67",
   "metadata": {},
   "source": [
    "## ML2HP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c792b75",
   "metadata": {},
   "source": [
    "### Ablation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d13ef3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping checkpoint ml2hp_loso_None_None-20250617-1111 as it has no valid subjects.\n",
      "Skipping checkpoint ml2hp_loso_convnextv2-t_None-20250616-0937 as it has no valid subjects.\n",
      "Skipping checkpoint ml2hp_loso_convnextv2-t_mlp-20250616-0937 as it has no valid subjects.\n",
      "\\begin{tabular}{llllllll}\n",
      "\\toprule\n",
      "Image backbone & Landmarks backbone & Precision (\\%) $\\uparrow$ & Recall (\\%) $\\uparrow$ & Accuracy (\\%) $\\uparrow$ & F1 (\\%) $\\uparrow$ & Inference time (ms) $\\downarrow$ & \\# Params (M) \\\\\n",
      "\\midrule\n",
      "- & Linear & 78.399 ± 8.842 & 77.416 ± 9.154 & 77.416 ± 9.154 & 76.533 ± 9.469 & 0.32 ± 0.01 & 2.0 \\\\\n",
      "- & MLP & 82.658 ± 7.349 & 81.153 ± 7.941 & 81.153 ± 7.941 & 80.366 ± 8.295 & 0.34 ± 0.01 & 4.2 \\\\\n",
      "CLIP-B \\cite{clip} & - & 51.469 ± 4.204 & 47.695 ± 3.601 & 47.695 ± 3.601 & 46.472 ± 3.939 & 2.48 ± 0.03 & 89.1 \\\\\n",
      "CLIP-B \\cite{clip} & Linear & 82.626 ± 7.938 & 81.506 ± 7.848 & 81.506 ± 7.848 & 80.954 ± 8.017 & 2.53 ± 0.04 & 91.0 \\\\\n",
      "CLIP-B \\cite{clip} & MLP & 87.651 ± 4.957 & 85.946 ± 5.025 & 85.946 ± 5.025 & 85.759 ± 5.157 & 2.54 ± 0.03 & 93.2 \\\\\n",
      "ConvNeXt V2-B \\cite{convnextv2} & - & 63.707 ± 2.637 & 59.239 ± 2.81 & 59.239 ± 2.81 & 58.861 ± 2.759 & 4.62 ± 0.03 & 89.8 \\\\\n",
      "ConvNeXt V2-B \\cite{convnextv2} & Linear & 84.541 ± 7.112 & 83.859 ± 6.415 & 83.859 ± 6.415 & 83.26 ± 6.853 & 4.65 ± 0.03 & 91.8 \\\\\n",
      "ConvNeXt V2-B \\cite{convnextv2} & MLP & 89.126 ± 3.901 & 88.186 ± 4.295 & 88.186 ± 4.295 & 87.937 ± 4.338 & 4.68 ± 0.05 & 94.0 \\\\\n",
      "ConvNeXt V2-T \\cite{convnextv2} & - & 59.171 ± 5.861 & 54.585 ± 4.882 & 54.585 ± 4.882 & 54.057 ± 4.666 & 2.95 ± 0.02 & 29.5 \\\\\n",
      "ConvNeXt V2-T \\cite{convnextv2} & Linear & 84.516 ± 7.891 & 83.979 ± 7.173 & 83.979 ± 7.173 & 83.384 ± 7.673 & 3.04 ± 0.04 & 31.4 \\\\\n",
      "ConvNeXt V2-T \\cite{convnextv2} & MLP & 89.252 ± 4.784 & 88.048 ± 4.855 & 88.048 ± 4.855 & 87.705 ± 5.021 & 3.06 ± 0.07 & 33.6 \\\\\n",
      "DINOv2-B \\cite{dinov2} & - & 62.536 ± 5.944 & 59.979 ± 6.301 & 59.979 ± 6.301 & 59.156 ± 6.684 & 2.68 ± 0.01 & 88.2 \\\\\n",
      "DINOv2-B \\cite{dinov2} & Linear & 83.426 ± 7.627 & 82.716 ± 7.266 & 82.716 ± 7.266 & 81.652 ± 7.569 & 2.71 ± 0.02 & 90.1 \\\\\n",
      "DINOv2-B \\cite{dinov2} & MLP & 88.473 ± 4.294 & 87.322 ± 4.256 & 87.322 ± 4.256 & 86.945 ± 4.578 & 2.74 ± 0.03 & 92.3 \\\\\n",
      "DINOv2-S \\cite{dinov2} & - & 56.951 ± 7.344 & 53.204 ± 6.145 & 53.204 ± 6.145 & 52.439 ± 5.752 & 2.69 ± 0.02 & 22.9 \\\\\n",
      "DINOv2-S \\cite{dinov2} & Linear & 83.652 ± 8.062 & 83.24 ± 6.908 & 83.24 ± 6.908 & 82.353 ± 7.43 & 2.7 ± 0.02 & 24.8 \\\\\n",
      "DINOv2-S \\cite{dinov2} & MLP & 89.061 ± 3.842 & 87.658 ± 4.067 & 87.658 ± 4.067 & 87.151 ± 4.322 & 2.74 ± 0.01 & 27.0 \\\\\n",
      "ResNet-18 \\cite{resnet, resnet_strikes_back} & - & 24.221 ± 5.569 & 14.385 ± 1.266 & 14.385 ± 1.266 & 6.206 ± 1.251 & 1.31 ± 0.01 & 12.3 \\\\\n",
      "ResNet-18 \\cite{resnet, resnet_strikes_back} & Linear & 78.673 ± 8.995 & 77.311 ± 8.926 & 77.311 ± 8.926 & 76.397 ± 9.01 & 1.33 ± 0.02 & 14.2 \\\\\n",
      "ResNet-18 \\cite{resnet, resnet_strikes_back} & MLP & 82.954 ± 6.401 & 80.133 ± 7.156 & 80.133 ± 7.156 & 79.109 ± 7.386 & 1.51 ± 0.3 & 16.4 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ablation_checkpoints_path = join(\"checkpoints\", \"ablation\")\n",
    "metrics_ablation = parse_results(ablation_checkpoints_path, dataset_name=\"ml2hp\")\n",
    "metrics_ablation = metrics_ablation[[\"Image backbone\", \"Landmarks backbone\", \"Precision (\\\\%) $\\\\uparrow$\", \"Recall (\\\\%) $\\\\uparrow$\", \"Accuracy (\\\\%) $\\\\uparrow$\", \"F1 (\\\\%) $\\\\uparrow$\", \"Inference time (ms) $\\\\downarrow$\", \"\\\\# Params (M)\"]]\n",
    "print(metrics_ablation.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9fa305",
   "metadata": {},
   "source": [
    "### Normalization table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6acef8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Validation', 'Image backbone', 'H image', 'V image',\n",
      "       'Landmarks backbone', 'H landmarks', 'V landmarks',\n",
      "       'Normalized landmarks', 'Accuracy (\\%) $\\uparrow$',\n",
      "       'F1 (\\%) $\\uparrow$', 'Precision (\\%) $\\uparrow$',\n",
      "       'Recall (\\%) $\\uparrow$', 'Loss $\\downarrow$', '\\# Params (M)',\n",
      "       'Inference time (ms) $\\downarrow$'],\n",
      "      dtype='object')\n",
      "\\begin{tabular}{lllllllll}\n",
      "\\toprule\n",
      "Normalized landmarks & H landmarks & H image & Precision (\\%) $\\uparrow$ & Recall (\\%) $\\uparrow$ & Accuracy (\\%) $\\uparrow$ & F1 (\\%) $\\uparrow$ & Inference time (ms) $\\downarrow$ & \\# Params (M) \\\\\n",
      "\\midrule\n",
      "\\cmark & \\cmark & \\cmark & 94.967 ± 2.522 & 94.432 ± 2.993 & 94.432 ± 2.993 & 94.319 ± 3.16 & 3.09 ± 0.04 & 33.6 \\\\\n",
      "\\cmark & \\cmark & \\xmark & 91.689 ± 3.067 & 90.887 ± 3.419 & 90.887 ± 3.419 & 90.599 ± 3.59 & 0.38 ± 0.02 & 4.2 \\\\\n",
      "\\xmark & \\cmark & \\cmark & 88.044 ± 3.369 & 86.314 ± 4.067 & 86.314 ± 4.067 & 86.363 ± 3.999 & 3.08 ± 0.04 & 33.6 \\\\\n",
      "\\xmark & \\cmark & \\xmark & 83.249 ± 4.14 & 79.678 ± 5.33 & 79.678 ± 5.33 & 79.661 ± 5.205 & 0.38 ± 0.03 & 4.2 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "norm_checkpoints_path = join(\"checkpoints\", \"normalization\")\n",
    "metrics_norm = parse_results(norm_checkpoints_path, dataset_name=\"ml2hp\")\n",
    "print(metrics_norm.columns)\n",
    "metrics_norm = metrics_norm[[\"Normalized landmarks\", \"H landmarks\", \"H image\", \"Precision (\\\\%) $\\\\uparrow$\", \"Recall (\\\\%) $\\\\uparrow$\", \"Accuracy (\\\\%) $\\\\uparrow$\", \"F1 (\\\\%) $\\\\uparrow$\", \"Inference time (ms) $\\\\downarrow$\", \"\\\\# Params (M)\"]]\n",
    "metrics_norm = metrics_norm.replace({\n",
    "    True: \"\\\\cmark\",\n",
    "    False: \"\\\\xmark\",\n",
    "})\n",
    "metrics_norm = metrics_norm.sort_values(by=[\"Normalized landmarks\", \"H image\"])\n",
    "print(metrics_norm.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb202c8b",
   "metadata": {},
   "source": [
    "### Results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "27d1fc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping checkpoint ml2hp_loso_convnextv2-t_mlp_h-images_h-landmarks-20250710-1542 as it has no valid subjects.\n",
      "Index(['Validation', 'Image backbone', 'H image', 'V image',\n",
      "       'Landmarks backbone', 'H landmarks', 'V landmarks',\n",
      "       'Normalized landmarks', 'Accuracy (\\%) $\\uparrow$',\n",
      "       'F1 (\\%) $\\uparrow$', 'Precision (\\%) $\\uparrow$',\n",
      "       'Recall (\\%) $\\uparrow$', 'Loss $\\downarrow$', '\\# Params (M)',\n",
      "       'Inference time (ms) $\\downarrow$'],\n",
      "      dtype='object')\n",
      "\\begin{tabular}{lllllllllll}\n",
      "\\toprule\n",
      "Method & H landmarks & V landmarks & H image & V image & Precision (\\%) $\\uparrow$ & Recall (\\%) $\\uparrow$ & Accuracy (\\%) $\\uparrow$ & F1 (\\%) $\\uparrow$ & Inference time (ms) $\\downarrow$ & \\# Params (M) \\\\\n",
      "\\midrule\n",
      "Baseline \\cite{icaart_baseline} & \\cmark & \\cmark & \\cmark & \\cmark & 80.63 ± 0.09 & 79.65 ± 0.09 & 79.65 ± 0.09 & 79.33 ± 0.09 & N/A & 89.5 \\\\\n",
      "Ours & \\cmark & \\cmark & \\cmark & \\cmark & 94.967 ± 2.522 & 94.432 ± 2.993 & 94.432 ± 2.993 & 94.319 ± 3.16 & 3.09 ± 0.04 & 33.6 \\\\\n",
      "Ours & \\cmark & \\cmark & \\xmark & \\xmark & 91.689 ± 3.067 & 90.887 ± 3.419 & 90.887 ± 3.419 & 90.599 ± 3.59 & 0.38 ± 0.02 & 4.2 \\\\\n",
      "Ours & \\cmark & \\xmark & \\cmark & \\xmark & 87.335 ± 4.399 & 86.006 ± 4.726 & 86.006 ± 4.726 & 85.86 ± 4.685 & 3.05 ± 0.04 & 33.1 \\\\\n",
      "Ours & \\cmark & \\xmark & \\xmark & \\xmark & 83.57 ± 4.806 & 81.896 ± 5.664 & 81.896 ± 5.664 & 81.468 ± 5.452 & 0.47 ± 0.02 & 3.7 \\\\\n",
      "Ours & \\xmark & \\cmark & \\xmark & \\cmark & 87.356 ± 3.578 & 85.888 ± 4.011 & 85.888 ± 4.011 & 85.658 ± 4.29 & 3.09 ± 0.04 & 33.1 \\\\\n",
      "Ours & \\xmark & \\cmark & \\xmark & \\xmark & 84.037 ± 4.8 & 82.715 ± 5.51 & 82.715 ± 5.51 & 82.192 ± 5.669 & 0.5 ± 0.03 & 3.7 \\\\\n",
      "Ours & \\xmark & \\xmark & \\cmark & \\cmark & 72.07 ± 6.665 & 69.403 ± 7.305 & 69.403 ± 7.305 & 69.009 ± 7.245 & 3.0 ± 0.03 & 29.5 \\\\\n",
      "Ours & \\xmark & \\xmark & \\cmark & \\xmark & 67.534 ± 5.924 & 63.929 ± 6.45 & 63.929 ± 6.45 & 63.601 ± 6.46 & 3.0 ± 0.03 & 29.5 \\\\\n",
      "Ours & \\xmark & \\xmark & \\xmark & \\cmark & 60.595 ± 6.36 & 56.063 ± 8.367 & 56.063 ± 8.367 & 55.582 ± 8.248 & 3.02 ± 0.03 & 29.5 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_checkpoints_path = join(\"checkpoints\", \"results\")\n",
    "metrics_results = parse_results(results_checkpoints_path, dataset_name=\"ml2hp\")\n",
    "print(metrics_results.columns)\n",
    "metrics_results[\"Method\"] = \"Ours\"\n",
    "metrics_results.loc[-1] = {\n",
    "    \"Method\": \"Baseline \\\\cite{icaart_baseline}\",\n",
    "    \"H landmarks\": True,\n",
    "    \"V landmarks\": True,\n",
    "    \"H image\": True,\n",
    "    \"V image\": True,\n",
    "    \"Precision (\\\\%) $\\\\uparrow$\": \"80.63 ± 0.09\",\n",
    "    \"Recall (\\\\%) $\\\\uparrow$\": \"79.65 ± 0.09\",\n",
    "    \"Accuracy (\\\\%) $\\\\uparrow$\": \"79.65 ± 0.09\",\n",
    "    \"F1 (\\\\%) $\\\\uparrow$\": \"79.33 ± 0.09\",\n",
    "    \"\\\\# Params (M)\": \"89.5\",\n",
    "}\n",
    "metrics_results = metrics_results[\n",
    "    [\n",
    "        \"Method\",\n",
    "        \"H landmarks\",\n",
    "        \"V landmarks\",\n",
    "        \"H image\",\n",
    "        \"V image\",\n",
    "        \"Precision (\\\\%) $\\\\uparrow$\",\n",
    "        \"Recall (\\\\%) $\\\\uparrow$\",\n",
    "        \"Accuracy (\\\\%) $\\\\uparrow$\",\n",
    "        \"F1 (\\\\%) $\\\\uparrow$\",\n",
    "        \"Inference time (ms) $\\\\downarrow$\",\n",
    "        \"\\\\# Params (M)\",\n",
    "    ]\n",
    "]\n",
    "metrics_results = metrics_results.replace(\n",
    "    {\n",
    "        True: \"\\\\cmark\",\n",
    "        False: \"\\\\xmark\",\n",
    "        None: \"N/A\",\n",
    "    }\n",
    ")\n",
    "metrics_results = metrics_results.sort_values(\n",
    "    by=[\"Method\", \"H landmarks\", \"V landmarks\", \"H image\", \"V image\"]\n",
    ")\n",
    "print(metrics_results.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ab636",
   "metadata": {},
   "source": [
    "## MMHGDHGR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f320da",
   "metadata": {},
   "source": [
    "### Results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c2883348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Validation', 'Image backbone', 'H image', 'V image',\n",
      "       'Landmarks backbone', 'H landmarks', 'V landmarks',\n",
      "       'Normalized landmarks', 'Accuracy (\\%) $\\uparrow$',\n",
      "       'F1 (\\%) $\\uparrow$', 'Precision (\\%) $\\uparrow$',\n",
      "       'Recall (\\%) $\\uparrow$', 'Loss $\\downarrow$', '\\# Params (M)',\n",
      "       'Inference time (ms) $\\downarrow$'],\n",
      "      dtype='object')\n",
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "Method & Validation & H landmarks & H image & Precision (\\%) $\\uparrow$ & Recall (\\%) $\\uparrow$ & Accuracy (\\%) $\\uparrow$ & F1 (\\%) $\\uparrow$ & Inference time (ms) $\\downarrow$ & \\# Params (M) \\\\\n",
      "\\midrule\n",
      "Baseline paper \\cite{MultiModalHandGestureDataset} & simple & \\xmark & \\cmark & - & - & 96.02 ± N/A & - & N/A & N/A \\\\\n",
      "MDAI paper \\cite{gilmartin2023hand} & simple & \\cmark & \\cmark & - & - & 97.25 ± 0.25 & 97.23 ± 0.25 & N/A & 0.03 \\\\\n",
      "Ours & loso & \\cmark & \\cmark & 95.517 ± 3.331 & 94.927 ± 2.723 & 94.927 ± 2.723 & 94.882 ± 3.213 & 9.73 ± 0.35 & 32.7 \\\\\n",
      "Ours & loso & \\cmark & \\xmark & 94.996 ± 3.64 & 94.177 ± 2.931 & 94.177 ± 2.931 & 94.075 ± 3.295 & 0.7 ± 0.09 & 3.3 \\\\\n",
      "Ours & loso & \\xmark & \\cmark & 88.557 ± 6.325 & 87.48 ± 5.991 & 87.48 ± 5.991 & 86.877 ± 6.827 & 9.99 ± 1.44 & 29.5 \\\\\n",
      "Ours & simple & \\cmark & \\cmark & 94.949 ± nan & 94.813 ± nan & 94.813 ± nan & 94.815 ± nan & 10.41 ± nan & 32.7 \\\\\n",
      "Ours & simple & \\cmark & \\xmark & 94.961 ± nan & 93.716 ± nan & 93.716 ± nan & 94.258 ± nan & 0.52 ± nan & 3.3 \\\\\n",
      "Ours & simple & \\xmark & \\cmark & 92.218 ± nan & 91.735 ± nan & 91.735 ± nan & 91.752 ± nan & 10.15 ± nan & 29.5 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_checkpoints_path = join(\"checkpoints\", \"mmhgdhgr_results\")\n",
    "metrics_results = parse_results(results_checkpoints_path, dataset_name=\"mmhgdhgr\")\n",
    "print(metrics_results.columns)\n",
    "metrics_results[\"Method\"] = \"Ours\"\n",
    "metrics_results = pd.concat(\n",
    "    [\n",
    "        metrics_results,\n",
    "        pd.DataFrame(\n",
    "            [\n",
    "                {\n",
    "                    \"Method\": \"MDAI paper \\\\cite{gilmartin2023hand}\",\n",
    "                    \"Validation\": \"simple\",\n",
    "                    \"H landmarks\": True,\n",
    "                    \"H image\": True,\n",
    "                    \"Precision (\\\\%) $\\\\uparrow$\": \"-\",\n",
    "                    \"Recall (\\\\%) $\\\\uparrow$\": \"-\",\n",
    "                    \"Accuracy (\\\\%) $\\\\uparrow$\": \"97.25 ± 0.25\",\n",
    "                    \"F1 (\\\\%) $\\\\uparrow$\": \"97.23 ± 0.25\",\n",
    "                    \"\\\\# Params (M)\": \"0.03\",\n",
    "                },\n",
    "                {\n",
    "                    \"Method\": \"Baseline paper \\\\cite{MultiModalHandGestureDataset}\",\n",
    "                    \"Validation\": \"simple\",\n",
    "                    \"H landmarks\": False,\n",
    "                    \"H image\": True,\n",
    "                    \"Precision (\\\\%) $\\\\uparrow$\": \"-\",\n",
    "                    \"Recall (\\\\%) $\\\\uparrow$\": \"-\",\n",
    "                    \"Accuracy (\\\\%) $\\\\uparrow$\": \"96.02 ± N/A\",\n",
    "                    \"F1 (\\\\%) $\\\\uparrow$\": \"-\",\n",
    "                },\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# metrics_results.loc[-1] = {\n",
    "#     \"Method\": \"SUYN paper \\\\cite{icaart_baseline}\",\n",
    "#     \"H landmarks\": True,\n",
    "#     \"H image\": True,\n",
    "#     \"Precision (\\\\%) $\\\\uparrow$\"\n",
    "# : \"-\",\n",
    "#     \"Recall (\\\\%) $\\\\uparrow$\": \"-\",\n",
    "#     \"Accuracy (\\\\%) $\\\\uparrow$\": \"97.25 ± 0.25\",\n",
    "#     \"F1 (\\\\%) $\\\\uparrow$\": \"97.23 ± 0.25\",\n",
    "# }\n",
    "# metrics_results.loc[-1] = {\n",
    "#     \"Method\": \"Baseline \\\\cite{mmhgdhgr}\",\n",
    "#     \"H landmarks\": True,\n",
    "#     \"V landmarks\": True,\n",
    "#     \"H image\": True,\n",
    "#     \"V image\": True,\n",
    "#     \"Precision (\\\\%) $\\\\uparrow$\": \"-\",\n",
    "#     \"Recall (\\\\%) $\\\\uparrow$\": \"-\",\n",
    "#     \"Accuracy (\\\\%) $\\\\uparrow$\": \"97.25 ± 0.25\",\n",
    "#     \"F1 (\\\\%) $\\\\uparrow$\": \"97.23 ± 0.25\",\n",
    "# }\n",
    "metrics_results = metrics_results[\n",
    "    [\n",
    "        \"Method\",\n",
    "        \"Validation\",\n",
    "        \"H landmarks\",\n",
    "        \"H image\",\n",
    "        \"Precision (\\\\%) $\\\\uparrow$\",\n",
    "        \"Recall (\\\\%) $\\\\uparrow$\",\n",
    "        \"Accuracy (\\\\%) $\\\\uparrow$\",\n",
    "        \"F1 (\\\\%) $\\\\uparrow$\",\n",
    "        \"Inference time (ms) $\\\\downarrow$\",\n",
    "        \"\\\\# Params (M)\",\n",
    "    ]\n",
    "]\n",
    "metrics_results = metrics_results.replace(\n",
    "    {\n",
    "        True: \"\\\\cmark\",\n",
    "        False: \"\\\\xmark\",\n",
    "        None: \"N/A\",\n",
    "    }\n",
    ")\n",
    "metrics_results = metrics_results.sort_values(\n",
    "    by=[\"Method\", \"Validation\", \"H landmarks\", \"H image\"]\n",
    ")\n",
    "print(metrics_results.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb015274",
   "metadata": {},
   "source": [
    "## Tiny HGR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f379094",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7c9cb9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Validation', 'Image backbone', 'H image', 'V image',\n",
      "       'Landmarks backbone', 'H landmarks', 'V landmarks',\n",
      "       'Normalized landmarks', 'Accuracy (\\%) $\\uparrow$',\n",
      "       'F1 (\\%) $\\uparrow$', 'Precision (\\%) $\\uparrow$',\n",
      "       'Recall (\\%) $\\uparrow$', 'Loss $\\downarrow$', '\\# Params (M)',\n",
      "       'Inference time (ms) $\\downarrow$'],\n",
      "      dtype='object')\n",
      "\\begin{tabular}{llllllllll}\n",
      "\\toprule\n",
      "Method & Validation & H landmarks & H image & Precision (\\%) $\\uparrow$ & Recall (\\%) $\\uparrow$ & Accuracy (\\%) $\\uparrow$ & F1 (\\%) $\\uparrow$ & Inference time (ms) $\\downarrow$ & \\# Params (M) \\\\\n",
      "\\midrule\n",
      "Baseline paper \\cite{TinyDatasetRecognition} & simple & \\cmark & \\cmark & - & - & 85.30 ± N/A & - & N/A & - \\\\\n",
      "MDAI paper \\cite{gilmartin2023hand} & simple & \\cmark & \\xmark & - & - & 98.22 ± 0.06 & 98.23 ± 0.06 & N/A & 0.03 \\\\\n",
      "Ours & loso & \\cmark & \\cmark & 99.005 ± 1.64 & 98.702 ± 2.715 & 98.702 ± 2.715 & 98.716 ± 2.664 & 10.05 ± 0.33 & 32.7 \\\\\n",
      "Ours & loso & \\cmark & \\xmark & 99.068 ± 1.626 & 98.796 ± 2.524 & 98.796 ± 2.524 & 98.811 ± 2.481 & 0.82 ± 0.78 & 3.3 \\\\\n",
      "Ours & loso & \\xmark & \\cmark & 89.825 ± 8.331 & 87.221 ± 10.813 & 87.221 ± 10.813 & 86.825 ± 11.182 & 10.15 ± 0.26 & 29.5 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_checkpoints_path = join(\"checkpoints\", \"tiny_hgr_results\")\n",
    "metrics_results = parse_results(results_checkpoints_path, dataset_name=\"tiny_hgr\")\n",
    "print(metrics_results.columns)\n",
    "metrics_results[\"Method\"] = \"Ours\"\n",
    "metrics_results = pd.concat(\n",
    "    [\n",
    "        metrics_results,\n",
    "        pd.DataFrame(\n",
    "            [\n",
    "                {\n",
    "                    \"Method\": \"MDAI paper \\\\cite{gilmartin2023hand}\",\n",
    "                    \"Validation\": \"simple\",\n",
    "                    \"H landmarks\": True,\n",
    "                    \"H image\": False,\n",
    "                    \"Precision (\\\\%) $\\\\uparrow$\": \"-\",\n",
    "                    \"Recall (\\\\%) $\\\\uparrow$\": \"-\",\n",
    "                    \"Accuracy (\\\\%) $\\\\uparrow$\": \"98.22 ± 0.06\",\n",
    "                    \"F1 (\\\\%) $\\\\uparrow$\": \"98.23 ± 0.06\",\n",
    "                    \"\\\\# Params (M)\": \"0.03\",\n",
    "                },\n",
    "                {\n",
    "                    \"Method\": \"Baseline paper \\\\cite{TinyDatasetRecognition}\",\n",
    "                    \"Validation\": \"simple\",\n",
    "                    \"H landmarks\": True,\n",
    "                    \"H image\": True,\n",
    "                    \"Precision (\\\\%) $\\\\uparrow$\": \"-\",\n",
    "                    \"Recall (\\\\%) $\\\\uparrow$\": \"-\",\n",
    "                    \"Accuracy (\\\\%) $\\\\uparrow$\": \"85.30 ± N/A\",\n",
    "                    \"F1 (\\\\%) $\\\\uparrow$\": \"-\",\n",
    "                    \"\\\\# Params (M)\": \"-\",\n",
    "                },\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# metrics_results.loc[-1] = {\n",
    "#     \"Method\": \"SUYN paper \\\\cite{icaart_baseline}\",\n",
    "#     \"H landmarks\": True,\n",
    "#     \"H image\": True,\n",
    "#     \"Precision (\\\\%) $\\\\uparrow$\"\n",
    "# : \"-\",\n",
    "#     \"Recall (\\\\%) $\\\\uparrow$\": \"-\",\n",
    "#     \"Accuracy (\\\\%) $\\\\uparrow$\": \"97.25 ± 0.25\",\n",
    "#     \"F1 (\\\\%) $\\\\uparrow$\": \"97.23 ± 0.25\",\n",
    "# }\n",
    "# metrics_results.loc[-1] = {\n",
    "#     \"Method\": \"Baseline \\\\cite{mmhgdhgr}\",\n",
    "#     \"H landmarks\": True,\n",
    "#     \"V landmarks\": True,\n",
    "#     \"H image\": True,\n",
    "#     \"V image\": True,\n",
    "#     \"Precision (\\\\%) $\\\\uparrow$\": \"-\",\n",
    "#     \"Recall (\\\\%) $\\\\uparrow$\": \"-\",\n",
    "#     \"Accuracy (\\\\%) $\\\\uparrow$\": \"97.25 ± 0.25\",\n",
    "#     \"F1 (\\\\%) $\\\\uparrow$\": \"97.23 ± 0.25\",\n",
    "# }\n",
    "metrics_results = metrics_results[\n",
    "    [\n",
    "        \"Method\",\n",
    "        \"Validation\",\n",
    "        \"H landmarks\",\n",
    "        \"H image\",\n",
    "        \"Precision (\\\\%) $\\\\uparrow$\",\n",
    "        \"Recall (\\\\%) $\\\\uparrow$\",\n",
    "        \"Accuracy (\\\\%) $\\\\uparrow$\",\n",
    "        \"F1 (\\\\%) $\\\\uparrow$\",\n",
    "        \"Inference time (ms) $\\\\downarrow$\",\n",
    "        \"\\\\# Params (M)\",\n",
    "    ]\n",
    "]\n",
    "metrics_results = metrics_results.replace(\n",
    "    {\n",
    "        True: \"\\\\cmark\",\n",
    "        False: \"\\\\xmark\",\n",
    "        None: \"N/A\",\n",
    "    }\n",
    ")\n",
    "metrics_results = metrics_results.sort_values(\n",
    "    by=[\"Method\", \"Validation\", \"H landmarks\", \"H image\"]\n",
    ")\n",
    "print(metrics_results.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d80458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2hp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
